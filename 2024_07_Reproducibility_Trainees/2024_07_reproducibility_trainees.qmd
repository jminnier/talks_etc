---
title: "Rigor and Reproducibility in Data Science"
subtitle: "Summer Students"
author: "Jessica Minnier, PhD<br><span style = 'font-size: 80%;'>Associate Professor of Biostatistics<br>OHSU-PSU School of Public Health<br>Knight Cancer Institute Biostatistics Shared Resource<br>Oregon Health & Science University</span>"
date: "July 30, 2024"
format: 
  revealjs:
      incremental: false
      scrollable: true
      chalkboard: true
      theme: [css/sky_modified_smaller_font.scss]
      width:  1100 #default 1050
      height: 825  #default 700
      slide-number: true
      html-math-method: mathjax
      footer: '[bit.ly/repro_ds_2024](https://bit.ly/repro_ds_2024)'
  # html:
  #   link-external-newwindow: true
  #   toc: true
execute:
  echo: false
  freeze: auto  # re-render only when source changes
# editor: visual
editor_options: 
  chunk_output_type: inline
---

```{r}
#| label: "setup" 
#| include: false
#| message: false
#| warning: false

library(tidyverse)
library(RefManageR)
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           cite.style = "alphabetic",
           style = "markdown",
           hyperlink = FALSE,
           dashed = FALSE)
myBib <- ReadBib("./minnier_bibliography.bib", check = FALSE)
```

# Introduction

<center><img src="ReproducibleJourney.jpg" width="65%" height="65%"/><a href="https://zenodo.org/record/3695300#.XsRP6BNKgqI"><br>Illustrations from the Turing Way book dashes; This image was created by Scriberia for The Turing Way community and is used under a CC-BY licence</a></center>


## Goals

-   Define reproducible research
-   Discuss current issues surrounding reproducibility
-   Important components of reproducibility
-   Relevance to data science and analysis

<center><img src="phdcomic_code.png" width="75%" height="75%"/><a href="http://phdcomics.com/"><br>PhD Comics by Jorge Cham</a></center>

## What is Reproducible Research?

::: columns
::: {.column width="50%"}
<center><img src="visual_repro_patil_leek.png" width="100%" height="100%"/><a href="https://www.biorxiv.org/content/10.1101/066803v1.full"><br>Patil, Peng, & Leek 2016</a></center>
:::

::: {.column width="50%"}
**Reproducibility:** ability to recompute data analytic results given the data set and knowledge of the data analysis pipeline

**Replicability:** the chance that an independent experiment targeting the same scientific question will produce a consistent result

-- `r Cite(key="peng2011reproducible", bib=myBib, textual = TRUE, .opts=list(cite.style="authoryear"))` "Reproducible research in computational science" and `r Cite(key="Leek:2015aa", bib=myBib, textual = TRUE, .opts=list(cite.style="authoryear"))` "Opinion: Reproducible research can still be wrong: Adopting a prevention approach"
:::
:::



## 

<center><img src="ReproducibleDefinitionGrid.jpg" width="85%" height="85%"/><a href="https://zenodo.org/record/3695300#.XsRP6BNKgqI"><br>Illustrations from the Turing Way book dashes; This image was created by Scriberia for The Turing Way community and is used under a CC-BY licence</a></center>

## Reproducible = Replicable + Transparant

> **Replicability** has been a key part of scientific inquiry from perhaps the 1200s. It has even been called the "demarcation between science and non-science."

-- `r Cite(bib=myBib,key="gandrud2013reproducible",textual=TRUE, .opts=list(cite.style="authoryear"))` book "Reproducible Research with R and R Studio" and references therein, including [Roger Bacon's "Opera quaedam hactenus inedita Vol. 1" from 1267](https://books.google.com/books?id=wMUKAAAAYAAJ)

## What are the different kinds of reproducibile research?

Victoria Stodden, a prominent scholar on this topic, has identified some useful distinctions in reproducible research:

> **Computational reproducibility**: when detailed information is provided about code, software, hardware and implementation details.
>
> **Empirical reproducibility**: when detailed information is provided about non-computational empirical scientific experiments and observations. In practice this is enabled by making data freely available, as well as details of how the data was collected.
>
> **Statistical reproducibility**: when detailed information is provided about the choice of statistical tests, model parameters, threshold values, etc. This mostly relates to pre-registration of study design to prevent p-value hacking and other manipulations.

[ROpenSci Reproducibility Guide](http://ropensci-archive.github.io/reproducibility-guide/sections/introduction/)

## Reproducibility in Data Science

> "Reproducibility is important because it is the **only thing that an investigator can guarantee about a study.**"
>
> "**a study can be reproducible and still be wrong**"

-- Roger Peng's 2014 blog post on Simply Statistics ["The Real Reason Reproducible Research is Important"](http://simplystatistics.org/2014/06/06/the-real-reason-reproducible-research-is-important/) also see `r Cite(bib=myBib,key="peng2011reproducible",textual=TRUE, .opts=list(cite.style="authoryear"))` "Reproducible research in computational science"



## Early notions of reproducibility: "Claerbout's Principle"

> An **article** about computational science in a scientific publication is not the scholarship itself, it is **merely advertising of the scholarship**. The actual scholarship is the complete software development environment and the complete set of instructions which generate the figures.

-   `r Cite(bib=myBib,key="claerbout1992electronic",textual=TRUE, .opts=list(cite.style="authoryear"))` "Electronic documents give reproducible research a new meaning"
-   `r Cite(bib=myBib,key="buckheit1995wavelab",textual=TRUE, .opts=list(cite.style="authoryear"))` "Wavelab and reproducible research"
-   `r Cite(key="schwab2000making", bib=myBib, textual = TRUE, .opts=list(cite.style="authoryear"))` "Making scientific computations reproducible"
-   `r Cite(bib=myBib,key="de2001reproducible",textual=TRUE, .opts=list(cite.style="authoryear"))` "Reproducible research. the bottom line"

> Jon F. Claerbout is the Cecil Green Professor Emeritus of Geophysics at Stanford University. He was one of the first scientists to emphasize that computational methods threaten the reproducibility of research unless open access is provided to both the data and the software underlying a publication.

# "Your primary collaborator is yourself 6 months from now, and your past self doesn't answer emails."

-- [Software Carprentry workshops](https://software-carpentry.org/)

# Current Issues and Discussion

## Nature series "Challenges in Irreproducible Research"

May 25, 2016 Editorial ["Reality check on reproducibility"](http://www.nature.com/news/reality-check-on-reproducibility-1.19961)


![](reproducibility-graphic-online1.jpg)


## Issues that affect scientific rigor and reproducibility

<center><img src="open_sci_training_handbook_issues.png" width="60%" height="60%"/><a href="https://open-science-training-handbook.github.io/Open-Science-Training-Handbook_EN/02OpenScienceBasics/04ReproducibleResearchAndDataAnalysis.html"><br>Open Science Training Handbook</a></center>

## Code availability in peer-reviewed journals

`r Cite(bib=myBib,key="stodden2013toward",textual=TRUE, .opts=list(cite.style="authoryear"))` "Toward Reproducible Computational Research: An Empirical Analysis of Data and Code Policy Adoption by Journals"

::: columns
::: {.column width="50%"}
![](jasa_repro_img.png)
:::

::: {.column width="50%"}
-   Studied change in policies between 2011-2012
-   Open data and code policy adoption vs.impact factor and publisher
-   Higher impact journals more likely to have open data and code policies
-   Scientific societies more likely to have open data and code policies than commercial publishers.
:::
:::


## Data sharing requirements in journals

`r Cite(bib=myBib,key="Vasilevsky_2017",textual=TRUE, .opts=list(cite.style="authoryear"))` ["Reproducible and reusable research: are journal data sharing policies meeting the mark?"](https://peerj.com/articles/3208/)

<center><img src="peerj1.png" width="100%" height="100%"/></center>

## Data management: FAIR principles (Findable, Accessible, Interoperable, Reusable)

::: columns
::: {.column width="50%"}
-   Make data available in trusted data repository
-   Include comprehensive metadata
-   Store in open (non-proprietary) formats
-   Attach a permanent identifier (i.e. DOI)

In Biomedical research, open access can be difficult/unethical.

`r Cite(bib=myBib,key="Wilkinson_2016",textual=TRUE, .opts=list(cite.style="authoryear"))`
:::

::: {.column width="50%"}
<center><img src="FAIRPrinciples.jpg" width="100%" height="100%"/><br><a href="https://zenodo.org/record/3695300#.XsRP6BNKgqI"><br>Illustrations from the Turing Way book dashes; This image was created by Scriberia for The Turing Way community and is used under a CC-BY licence</a></center>
:::
:::

## NIH requirements for grants (beginning Jan 2016, updated Jan 2019)

["Enhancing Reproducibility through Rigor and Transparency"](http://grants.nih.gov/grants/guide/notice-files/NOT-OD-15-103.html)

1.  *Rigor of the Prior Research*
    -   "describe the general strengths and weaknesses of the prior research being cited by the investigator as crucial to support the application."
    -   experimental design/power of prior studies used for hypothesis generation, weaknesses include different populations/species, unblinded, not adjusting for confounders
2.  *Rigorous Experimental Design*
3.  *Consideration of Sex and Other Relevant Biological Variables*
    -   "sex is a biological variable that is frequently ignored in animal study designs and analyses"
4.  *Authentication of Key Biological and/or Chemical Resources*
5.  *Implementation*

[NIH "Rigor and Reproducibility" Policy](http://grants.nih.gov/reproducibility/index.htm)

*Note:* Most of this is in regards to the science, design of experiment, chemical and biological methods. **Essentially no language describing reproducibility of analyses or data management for data or results generated by the grant.**

## NIH [Principles and Guidelines for Reporting Preclinical Research](http://www.nih.gov/research-training/rigor-reproducibility/principles-guidelines-reporting-preclinical-research)

Journals should aim to facilitate the interpretation and repetition of experiments as they have been conducted in the published study.

-   include policies for statistical reporting in information to authors
-   no limits or generous limits for methods sections
-   should use a **checklist** during editorial processing to ensure the reporting of key methodological and analytical information to reviewers and readers
-   Data and material sharing




## Checklists for Reproducibility

-   ["Checklists work to improve science"](https://www.nature.com/articles/d41586-018-04590-7) - Nature editorial, April 2018
-   In 2013, *Nature* announced that authors submitting manuscripts to *Nature* journals would need to complete a checklist addressing key factors underlying irreproducibility for reviewers and editors to assess during peer review
-   Survey of researchers who had published in a Nature journal between July 2016 and march 2017

> Of the 480 who responded, 49% thought that the checklist had improved the quality of research published in Nature (15% disagreed); 37% thought the checklist had improved quality in their field overall (20% disagreed).

Checklists can be useful for computational research in general.

An excellent example: [ROpenSci's Reproducibility Checklist](http://ropensci.github.io/reproducibility-guide/sections/checklist/)

## Reporting Guidelines

<center><img src="equator_network.png" width="95%" height="100%"/><a href="https://www.equator-network.org/"><br></a></center>

## e.g. ARRIVE Pre-clinical animal studies

<center><img src="arrive1.png" width="95%" height="100%"/><a href="https://arriveguidelines.org/resources/author-checklists/"><br></a></center>

## 

<center><img src="arrive2.png" width="95%" height="100%"/><a href="https://arriveguidelines.org/resources/author-checklists/"><br></a></center>


## Computational Reproducibility

::: columns
::: {.column width="50%"}
<br> `r Cite(bib=myBib,key="Stodden_2016",textual=TRUE, .opts=list(cite.style="authoryear"))` in *Science* Policy Forum

-   Share data, software, workflows, and details of computational environment in open trusted repositories
-   Persistent links, permanent identifiers for data, code, digital artifacts upon which the results depend
-   Enable credit for shared digital scholarly objects with citations
-   Adequately document to facilitate reuse
-   Use Open Licensing
-   Journals should conduct a reproducibility check
-   Funding agencies should instigate new research programs and pilot studies
:::

::: {.column width="50%"}
<br>

<center><img src="survey_nature.png" width="100%" height="100%"/><a href="https://media.nature.com/original/magazine-assets/d41586-018-04590-7/15675426"><br>Nature Survey 2017 results, n=480 authors</a></center>
:::
:::

# Reproducibility in Practice

## Data management

> "The basics of RDM \[Research Data Management\] that should be applied to every research project include: i) storing data carefully and securely (according to the appropriate standards in the case of sensitive data), ii) backing up frequently and in at least two separate locations, and iii) using a file naming convention so that others within and outside a project can understand a file’s content."

`r Cite(bib=myBib,key="hejblum2018",textual=TRUE, .opts=list(cite.style="authoryear"))`\

Resources: - [DMPonline](https://dmponline.dcc.ac.uk/) by the Digital Curation Centre for writing data management plans - [FAQs for Enabling FAIR Data](http://www.copdess.org/enabling-fair-data-project/enabling-fair-data-faqs/) - LabKey, open-source specimen and data management platform

## Software, workflow, and dependency management

Problems:

-   Software changes, new versions are released and older code breaks.
-   Files are removed or moved and all the code breaks.
-   One file is updated but the rest of the code/files are not updated.
-   You forgot which files depend on which other files, or what has been changed.

Solutions for Workflow:

-   **Automation** streamlined automation and documentation of the research process, e.g. editing files, moving input and output between different parts of your workflow, and compiling documents for publication (shell programs, `make`); in python: snakemake, in R: drake

Solutions for Dependency:

-   **Preservation** of the environment (code, data, software) with virtualisation, i.e. Docker, VMware, VirtualBox, packrat for R package management

[ROpenSci Reproducibility Guide](http://ropensci.github.io/reproducibility-guide/sections/introduction/)

## Archiving and citability

-   Long-term availability of code and data
-   Popular repositories for data: Zenodo, Dryad, Genbank, GEO
-   Popular repositories for code: GitHub, bitbucket, Bioconductor, CRAN PyPI
-   Citability: Digital Object Identifier (DOI) for code and data

<center><img src="kunzmann_table_repos.png" width="65%" height="100%"/><br>[Hejblum et al  "Realistic and Robust Reproducible Research for Biostatistics"](https://www.preprints.org/manuscript/202006.0002/v1)</center>


## Literate Programming

::: columns
::: {.column width="50%"} 

> Literate programming is an approach to programming introduced by Donald Knuth in which a program is given as an explanation of the program logic in a natural language, such as English, interspersed with snippets of macros and traditional source code, from which a compilable source code can be generated. `r Cite(bib=myBib,key="knuth1984literate",textual=FALSE, .opts=list(cite.style="authoryear"))`

Current implementations weave code, documentation, results, and other output in the same document.

Examples: [quarto](https://quarto.org/) (for R, python, other languages), [knitr](http://yihui.name/knitr/) (for R), Sweave; Jupyter notebooks (for python) [SASweave](http://homepage.cs.uiowa.edu/~rlenth/SASweave/), Statrep (for SAS); [StatWeave](http://homepage.stat.uiowa.edu/~rlenth/StatWeave/) (for STATA)
:::
::: {.column width="50%"}
This is quarto (presentation made with quarto+RStudio):

```{r, message=FALSE, warning=FALSE, echo=TRUE}
library(survival)
leukemia.surv <- survfit(Surv(time, status) ~ x, data = aml) 
plot(leukemia.surv, lty = 2:3) 
legend(100, .9, c("Maintenance", "No Maintenance"), lty = 2:3) 
title("Kaplan-Meier Curves\nfor AML Maintenance Study")
```
:::
:::

## Why Use Version Control?

::: columns
::: {.column width="60%"}

<center><img src="ProjectHistory.jpg" width="100%" height="100%"/><a href="https://zenodo.org/record/3695300#.XsRP6BNKgqI"><br>Illustrations from the Turing Way book dashes; This image was created by Scriberia for The Turing Way community and is used under a CC-BY licence</a></center>
:::
::: {.column width="40%"}
<center><img src="phdcomic_version.png" width="95%" height="100%"/><a href="http://www.phdcomics.com"><br>PhD Comics by Jorge Cham</a></center>
:::
:::

## Version Control

::: columns
::: {.column width="50%"}
-   A system that tracks and records changes to file(s)
-   Allows for collaborative work on code
-   i.e. **git** manages changes in data, code, figures, manuscripts, etc.
-   online git repositories include: GitHub, bitbucket, GitLab
-   more sophisticated/lightweight than track changes in Word/google docs

Resources: - [Software Carpentry "Version Control w/Git"](https://swcarpentry.github.io/git-novice/) - [Github tutorials](https://try.github.io/) - [Happy Git and GitHub for the useR - Jenny Bryan, Jim Hester](https://happygitwithr.com/)
:::

::: {.column width="50%"}
<center><img src="VersionControl.jpg" width="100%" height="100%"/><a href="https://zenodo.org/record/3695300#.XsRP6BNKgqI"><br>Illustrations from the Turing Way book dashes; This image was created by Scriberia for The Turing Way community and is used under a CC-BY licence</a></center>
:::
:::

## Why Use Version Control?

> Have you ever:
>
> -   Made a change to code, realised it was a mistake and wanted to revert back?
> -   Lost code or had a backup that was too old?
> -   Had to maintain multiple versions of a product?
> -   Wanted to see the difference between two (or more) versions of your code?
> -   Wanted to prove that a particular change broke or fixed a piece of code?
> -   Wanted to review the history of some code?
> -   Wanted to submit a change to someone else's code?
> -   Wanted to share your code, or let other people work on your code?
> -   Wanted to see how much work is being done, and where, when and by whom?
> -   Wanted to experiment with a new feature without interfering with working code?
>
> In these cases, and no doubt others, **a version control system should make your life easier.**

[Stack Overflow question: Why should I use version control?](http://stackoverflow.com/questions/1408450/why-should-i-use-version-control)


# Make a Plan

## "Ten Simple Rules for Reproducible Computational Research"

-   **Rule 1: For Every Result, Keep Track of How It Was Produced**
-   **Rule 2: Avoid Manual Data Manipulation Steps**
-   Rule 3: Archive the Exact Versions of All External Programs Used
-   Rule 4: Version Control All Custom Scripts
-   Rule 5: Record All Intermediate Results, When Possible in Standardized Formats
-   Rule 6: For Analyses That Include Randomness, Note Underlying Random Seeds
-   Rule 7: Always Store Raw Data behind Plots
-   Rule 8: Generate Hierarchical Analysis Output, Allowing Layers of Increasing Detail to Be Inspected
-   Rule 9: Connect Textual Statements to Underlying Results
-   **Rule 10: Provide Public Access to Scripts, Runs, and Results**

`r Cite(bib=myBib,key="sandve2013ten",textual=TRUE, .opts=list(cite.style="authoryear"))`

## Example ideals for a computational group

-   Literate programming (use R Markdown)
-   Agree on best practices for writing code (i.e. [ROpenSci's Reproducibility & Writing Code Guide](http://ropensci.github.io/reproducibility-guide/sections/writingCode/) and "Best Practices for Scientific Computing" `r Cite(bib=myBib,key="wilson2014best",textual=TRUE, .opts=list(cite.style="authoryear"))`
-   Agree on folder structure, naming conventions
-   Use html web-based output
    -   [see Matthew Shotwell's slides](http://biostatmatt.com/uploads/shotwell-interface-2011.pdf)
    -   nearly universal compatibility
    -   persistent
    -   images handled more naturally
    -   avoid changes (i.e. in Word)
-   Use `make` files to rerun analyses when certain files change
-   Version/revision control systems such as git for all files
-   Version control of data, stored with backup in persistent location
-   Store metadata, readme files
-   Software/package versions need to be maintained

## Resources

### Recommended Books

-   [Stodden, Victoria, Friedrich Leisch, and Roger D. Peng, eds. Implementing reproducible research. CRC Press, 2014.](https://www.crcpress.com/Implementing-Reproducible-Research/Stodden-Leisch-Peng/9781466561595)
-   [Gandrud, Christopher. Reproducible Research with R and R Studio. CRC Press, 2013.](https://www.crcpress.com/Reproducible-Research-with-R-and-R-Studio/Gandrud/9781466572843)
-   [Xie, Yihui. Dynamic Documents with R and knitr. Vol. 29. CRC Press, 2013.](https://www.crcpress.com/Dynamic-Documents-with-R-and-knitr/Xie/9781482203530)

### Online classes

-   Karl Broman's class "Tools for Reproducible Research" at UWisconsin-Madison <http://kbroman.org/Tools4RR/>
-   "Reproducible Research" by Johns Hopkins on Coursera (Peng, Leek, Caffo) <https://www.coursera.org/learn/reproducible-research>
-   Learn git: <https://try.github.io/levels/1/challenges/1>

### NIH Rigor & Reproducibility Resources

-   Website: <http://grants.nih.gov/reproducibility/index.htm>
-   FAQs: <http://grants.nih.gov/reproducibility/faqs.htm>
-   NIH Training Module: <https://grants.nih.gov/reproducibility/module_1/presentation.html>

### Websites/slides/blogs

-   ROpenSci's "Reproducibility in Science" [guide](http://ropensci-archive.github.io/reproducibility-guide/) including the [reproducibility checklist](http://ropensci-archive.github.io/reproducibility-guide/sections/checklist)
-   [Open Science Training Handbook](https://open-science-training-handbook.github.io/Open-Science-Training-Handbook_EN/)
-   [The Practice of Reproducible Research: Case Studies and Lessons from the Data-Intensive Sciences](http://www.practicereproducibleresearch.org/) (2018) eds. Kitzes, Turek, Deniz
-   Victoria Stodden's [list of talks](http://web.stanford.edu/~vcs/Talks.html) on various topics from "Reproducibility: Breakin' it Down" to "Legal Issues in Reproducible Research"
-   Matthew Shotwell's slides (2011) ["Approaches and Barriers to Reproducible Practices in Biostatistics"](http://biostatmatt.com/uploads/shotwell-interface-2011.pdf)
-   M Shotwell and JM Álvarez' slides ["Approaches and Barriers to Reproducible Practices in Biostatistics"](http://biostatmatt.com/uploads/shotwell-interface-2011.pdf) and ["Barriers to Reproducible Research and a Web-Based Solution"](http://biostat.mc.vanderbilt.edu/wiki/pub/Main/MattShotwell/MSRetreat2013Slides.pdf)
-   ROpenSci's blog post ["Reproducible research is still a challenge"](https://ropensci.org/blog/2014/06/09/reproducibility/) by R. FitzJohn, M. Pennell, A. Zanne, W. Cornwell, June 9, 2014, describes the experience of running an example analysis
-   Stodden (2014) ["What scientific idea is ready for retirement?"](https://www.edge.org/response-detail/25340)
-   StackOverflow question ["Why should I use version control?"](http://stackoverflow.com/questions/1408450/why-should-i-use-version-control)
-   Karl Broman's class ["Tools for Reproducible Research" resource page](http://kbroman.org/Tools4RR/pages/resources.html) and ["Why Reproducibility is Hard"](https://kbroman.wordpress.com/2015/09/09/reproducibility-is-hard/)
-   [CRAN's task view on Reproducible Research](https://cran.r-project.org/web/views/ReproducibleResearch.html)


## References

```{r}
#| results: "asis"
PrintBibliography(myBib)
```

## Thank you!

### Contact info:

-   Jessica Minnier: *minnier\@ohsu.edu*

### This workshop info:

-   Code for these slides are on github, with links to other talks and course materials: [jminnier/talks_etc](https://github.com/jminnier/talks_etc)

### This presentation is made with Quarto + RStudio

This is an R Markdown presentation. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

This is a document written in plain text (.qmd file) with text and R code embedded with the special syntax. Within RStudio when you click the **render** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document.
