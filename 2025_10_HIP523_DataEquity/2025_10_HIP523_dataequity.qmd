---
title: "Beyond 'Adjusting for Race:' Data Equity in Clinical Research"
subtitle: "HIP523"
author: "Jessica Minnier, PhD<br><span style = 'font-size: 80%;'>Associate Professor of Biostatistics<br>OHSU-PSU School of Public Health<br>Knight Cancer Institute Biostatistics Shared Resource<br>Senior Statistician for APOM<br>Oregon Health & Science University</span><br><br>[bit.ly/hip25_data_eq](https://bit.ly/hip25_data_eq)"
date: "October 21, 2025"
format: 
  revealjs:
      incremental: false
      scrollable: true
      chalkboard: true
      theme: [css/sky_modified_smaller_font.scss]
      width:  1200 #1100 #default 1050
      height: 850 #825  #default 700
      slide-number: true
      html-math-method: mathjax
      title-slide-attributes:
        data-background-image: img/ohsu_logo.jpg
        data-background-size: 10%
        data-background-position: 90% 60%
      #logo: img/ohsu_logo.jpg
      #footer: '[bit.ly/repro_ds_2024](https://bit.ly/repro_ds_2024)'
  # html:
  #   link-external-newwindow: true
  #   toc: true
execute:
  echo: false
  freeze: auto  # re-render only when source changes
# editor: visual
editor_options: 
  chunk_output_type: inline
---

```{r}
#| label: "setup" 
#| include: false
#| message: false
#| warning: false

library(tidyverse)
library(RefManageR)
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           cite.style = "alphabetic",
           style = "markdown",
           hyperlink = TRUE,
           dashed = FALSE)
myBib <- ReadBib(here::here("2025_10_DataEquityAPOM_GR","minnier_bibliography.bib"), check = FALSE)
```




## Learning Objectives

::: {.fragment}
-   Define data equity and its importance in statistical analysis
-   Understand key considerations when including sex and race in multivariable models
-   Examine best practices for incorporating sex as a biological variable (SABV)
-   Explore the complexities of race and ethnicity in research through examples
-   Discuss the role of social determinants of health (SDOH) in research]
:::

::: {.fragment}

At the conclusion of this activity, participants will be able to:

-   Describe key concepts of data equity
-   Describe common sources of bias in clinical research
-   Identify appropriate biostatistical strategies to evaluate and address data inequities
:::

:::{.notes}
Good morning, everyone. Thank you for being here. My name is Jessica Minnier, and I'm an Associate Professor of Biostatistics. I have been at OHSU for 12 years, but I have recently started serving as a Statistician for APOM, along with Shauna Rakshe. So this is kind my hello and introduction to you all, and I look forward to working with some you in the future. Today, I want to talk about a topic that is becoming increasingly critical and relevant in our field: which is Data Equity in Clinical Research. Data equity is a vague term that can mean many things so I will try to define that, and also talk more broadly about how we think about characteristics such as race, sex, gender, social determinants of health, etc, when we approach our research design and data analysis.

The goal of this talk is to give you, as clinicians and researchers, a practical framework for thinking about equity at every stage of your research—from study design to the final interpretation of your results.

We could spend a long time talking about every kind of scenario here, but ultimately, the goal is for you to leave with the ability to describe these key concepts, identify common sources of bias in clinical research, and be more confident in choosing a biostatistical strategy that addresses and evaluates potential inequities in our data."
:::

# What is Data Equity?

::: {.fragment}
[![UMD Library Guide](img/legos_umd_lib.png){fig-alt="Pieces of yellow lego does not equal diverse lego people"}](https://lib.guides.umd.edu/ResearchEquity/DataEquity)
:::

:::{.notes}
"Let's start with the foundational question: What exactly is Data Equity?"
I don't know how interactive these early morning talks are, but if anyone has an idea, feel free to put in the chat.

In general we might think of this idea that populations are not homogenous, we each are individuals, and furthermore, there are subgroups of us that are historically marginalized and understudied in health research.
:::

## What is Data Equity?

::: {.incremental .highlight-last}
-   The consideration of issues of power, bias, and discrimination in how data is collected, analyzed, interpreted, and used

-   Ensuring research benefits all populations equitably, especially those historically marginalized or underrepresented

-   Recognition that data is not neutral - it reflects existing social structures and biases

-   Allow community and patient participation in the research process, ensure trust and accessibility, with the goal of data sovereignty

-   Ultimately, data equity seeks to achieve just, unbiased, and actionable insights that enhance care quality and reduce disparities across diverse patient populations
:::

::: {style="font-size: 70%;"}
References:

-   [Community Commons "An Introduction to Data Equity"](https://www.communitycommons.org/collections/An-Introduction-to-Data-Equity)
-   [CDC Foundation "Data Equity Principles"](https://www.cdcfoundation.org/HealthEquity/data-equity-principles)
-   [UMD Library Guide: Research Equity, Data Equity](https://lib.guides.umd.edu/ResearchEquity/DataEquity)
-   [Data.org](https://data.org/resources/what-is-data-equity-and-why-does-it-matter/)
:::

:::{.notes}
"More technically and at its core, data equity is the conscious consideration of power, bias, and discrimination in how we collect, analyze, interpret, and use data. It’s a commitment to ensuring that our research benefits all populations equitably, especially those who have been historically marginalized or underrepresented.

A key principle here is recognizing that data is not neutral; it inherently reflects the social structures and biases that exist in our world. Data equity also pushes us toward a more inclusive research model—one that involves community participation and builds trust, with the ultimate goal of data sovereignty, where communities have ownership over their own data. In the end, it’s about generating insights that are not just statistically sound, but also just, unbiased, and actionable, helping us reduce health disparities."
:::

## Data Equity Principles

[![CDC Foundation Data Equity Principles](img/cdc-foundation-data-equity-principles-life-cycle.png){fig-alt="CDC Foundation Data Equity Principles"}](https://www.cdcfoundation.org/data-equity-principles?inline)

:::{.notes}
The CDC Foundation has outlined a life cycle for data equity. As you can see, equity isn't a single step; it's a lens we must apply throughout the entire research process—from defining our purpose and collecting data to analyzing it and, crucially, sharing and acting on our findings.

Unsurprisingly, I gave a version of this talk a year ago, and the link to this figure that I had here was dead. So I found the original pdf and linked it, if you want to read further.
:::

# What is Equity-minded Research?

![](img/data_pres_team)
[Lummi.ai](https://www.lummi.ai/illustration/data-presentation-team-x1xh7)

:::{notes}
"This leads us to the idea of Equity-minded Research. What does that look like in practice?" If you have an idea, or example, feel free to shout it out or put it in the chat.
:::

## Equity-minded Research

::: {.incremental .highlight-last}
-   Recognize and define systemic factors
-   Inclusive data collection
-   [Representative sampling](https://www.nature.com/articles/s41591-023-02665-1)
-   Contextual analysis
    -   Researchers must understand and reflect on their own biases and assumptions, as well as identity and experiences relative to others ([positionality](https://www.urban.org/research/publication/exploring-individual-and-institutional-positionality))
-   Equitable interpretation
-   Responsible reporting
:::

::: {style="font-size: 70%;"}
References:

-   `r Cite(key="venkateswaran2023bringing", bib=myBib, textual = TRUE, .opts=list(cite.style="authoryear"))`
-   `r Cite(key="retzer2023toolkit", bib=myBib, textual = TRUE, .opts=list(cite.style="authoryear"))`
:::

:::{.notes}
Equity-minded research means we actively recognize and define the systemic factors that influence health outcomes. It starts with inclusive data collection and representative sampling. But it also requires contextual analysis. This is where the concept of positionality comes in—it’s the practice of researchers reflecting on our own biases, assumptions, and life experiences and how those might influence our work. Finally, it demands that we interpret our findings equitably and report them responsibly.
:::

## Example: Sampling

### Unrepresentative or skewed sampling can impact patient safety and outcome prediction

-   A clinical risk assessment tool trained on a homogeneous population can mis-classify risk for underrepresented groups
-   Rates of adverse events can be over- or under-estimated in certain groups

![](img/auc_ex_fig.png){fig-align="center"}

::: {.notes}
Let’s look at a concrete example of why this matters. Unrepresentative or skewed sampling can have real-world consequences for patient safety and outcome prediction. If for example, we train a clinical risk assessment tool on a mostly homogeneous population, it can easily misclassify risk for underrepresented groups, leading to poorer outcomes. For example, this figure illustrates how a imaginary prediction model can have excellent performance—a high AUC—in one group but perform poorly in another if the training data wasn't representative. This isn't just a statistical issue; it's a patient safety issue. It's not very ethical to use a tool to assess someone's risk of disease or adverse event when it is failing to do what it promises to do.
:::

## Common Data Equity Challenges

::::: columns
::: {.column width="50%"}
::: {.incremental .highlight-last}
-   Selection bias in sampling
    - Ex: research in large academic medical centers may exclude rural populations or those with limited access to care

-   Missing or incomplete data for certain populations
    - Ex: language barriers may lead to incomplete data
:::

:::

::: {.column width="50%"}
![](img/urban_rural.png)
:::
:::::

::: {.incremental .highlight-last}
-   Limited access to data collection resources
    - Ex: rural areas often lack infrastructure for comprehensive health data collection, resulting in urban-centric health policies
    - Ex: limited availability of trained medical interpreters for patients who speak less common languages, resulting in incomplete information for these populations
:::

:::{.notes}
So, what are the common hurdles? The first is selection bias. A lot of research happens in large academic medical centers, which can unintentionally exclude rural populations or those with limited access to care. Another is missing or incomplete data. For instance, language barriers can easily lead to incomplete records for certain patient groups. Similarly, limited access to data collection resources in a rural area might lead to more incomplete data.
:::
    
## Common Data Equity Challenges

::: {.incremental .highlight-last}
-   Inappropriate aggregation of diverse groups

    -   Ex: collapsing Asian American subgroups can mask disparities, [Haelle 2022, Association of Health Care Journalists](https://healthjournalism.org/blog/2022/08/how-improper-aggregation-of-racial-ethnic-groups-in-research-can-mask-health-disparities/)
    -   Ex: prevalence of asthma varies across US-born vs non-US-born Latinos `r Cite(key="marino2023disaggregating", bib=myBib, textual = TRUE, .opts=list(cite.style="authoryear"))`

-   Lack of contextual variables

    -   Ex: a study on post-op complications that focuses only on patient-level factors such as age, comorbidities, and procedure type but fails to include hospital-level factors like nurse-to-patient ratios, availability of specialized perioperative care units, etc.
    -   Ex: a study on asthma prevalence may fail to account for air quality or housing conditions, focusing on individual-level factors but missing community-level determinants of health
:::

:::{.notes}
Another major challenge is the inappropriate aggregation of diverse groups. For example, collapsing all Asian American subgroups into a single category can mask significant health disparities between, say, Vietnamese and Japanese populations. We found something similar in our own work, where the prevalence of asthma varied significantly between U.S.-born and non-U.S.-born Latinos.

We also see a lack of contextual variables. A study on postoperative complications might track patient comorbidities but completely miss hospital-level factors like nurse-to-patient ratios, which could be a powerful driver of the outcomes we're studying. Or, a study on asthma prevalence may fail to account for community level determinants of health such as air quality or housing conditions.

:::

## Common Data Equity Challenges

::: {.incremental .highlight-last}
-   Historical unethical studies and misuse of demographic data

    -   Many examples of unethical and harmful medical research on African Americans, leading to mistrust of medical research in the Black communities, leading to underpresentation in studies
    -   Tuskegee syphilis study is just one example `r Cite(key = "katz2006tuskegee", bib=myBib, textual = TRUE, .opts=list(cite.style="authoryear"))`
:::

:::{.notes}
And finally, we cannot ignore the historical context. Unethical studies, like the Tuskegee syphilis study, have created a deep and justified mistrust of medical research in many Black communities, leading to their underrepresentation in clinical trials and other studies. Acknowledging this history is the first step toward rebuilding that trust.
:::

# Sex and Gender Considerations

![NIH Sex and Gender](img/nih_sex_gender.png)

[NIH Sex and Gender](https://orwh.od.nih.gov/sex-gender)

:::{.notes}
"Now, let's pivot to a specific area: sex and gender."
:::

## Sex and Gender in Statistical Models

### Best Practices

::: {.incremental .highlight-last}
-   Distinguish between sex and gender variables
-   Consider both biological and social factors
-   Avoid binary assumptions
-   Document missing data patterns
:::

### Common Pitfalls

::: {.incremental .highlight-last}
-   Conflating sex and gender
-   Systemic lack of female representation (as well as omissions of transgender and intersex populations or persons with variations in sex characteristics)
-   Assuming homogeneity within groups
-   Overlooking interaction effects
-   Missing intersectional perspectives
:::

:::{.notes}
"In our models, it is crucial to distinguish between sex, which is biological, and gender, which is a social construct. Too often, these terms are used interchangeably, which is a significant pitfall. Best practice is to consider both biological and social factors, avoid assuming that sex or gender is a simple binary, and be transparent about how we handle missing data for these variables. A major pitfall in research has been the systemic lack of female representation in studies, as well as the near-total omission of transgender and intersex populations."

:::

## Sex as a Biological Variable (SABV)


### Key Considerations


-   Hormonal influences
-   Genetic differences
-   Physiological variations
-   Life-cycle changes



### Implementation Strategies

::: {.incremental .highlight-last}
-   Include adequate sample sizes for all sexes
-   Test for sex-specific effects
-   Report sex-disaggregated results
-   Consider sex-based biological mechanisms
:::


[National Institutes of Health (NIH) SABV Policy (2016)](https://orwh.od.nih.gov/sex-gender/orwh-mission-area-sex-gender-in-research/nih-policy-on-sex-as-biological-variable)



:::{.notes}

"In 2016, the NIH implemented the 'Sex as a Biological Variable' or SABV policy. This policy requires researchers to account for sex in the design, analysis, and reporting of vertebrate animal and human studies. This means we need adequate sample sizes for all sexes, we should be testing for sex-specific effects, and we must report sex-disaggregated results. This isn't just about fairness; it's about rigor and reproducibility, as biological mechanisms often differ significantly by sex."
:::

## Sex as a Biological Variable (SABV)

![NIH 4 Cs of Studying SABV](img/nih_sabv.png){fig-alt="NIH 4 Cs of Studying SABV"}

:::{.notes}
The NIH provides a helpful framework known as the '4 Cs.' We need to Consider SABV in our research questions, Collect and Characterize sex in our samples, and Communicate our sex-disaggregated findings
:::

# Race and Ethnicity in Research

> Race is a social construct, commonly used in epidemiologic research to adjust for confounding. However, adjustment of race may mask racial disparities, thereby perpetuating structural racism.

"We adjusted for race": now what? A systematic review... `r Cite(key = "swilley2023we", bib=myBib, textual = TRUE, .opts=list(cite.style="authoryear"))`


:::{.notes}
Alright, let's tackle one of the most complex and important topics in this discussion: Race and Ethnicity. There's a quote from a recent systematic review that I think sets up this discussion perfectly: 'Race is a social construct, commonly used in epidemiologic research to adjust for confounding. However, adjustment of race may mask racial disparities, thereby perpetuating structural racism'
:::

## Race and Ethnicity: Critical Considerations

::: {.incremental .highlight-last}
-   Race is a social construct, not biological
-   Substantial within-group variation
-   Historical context of racial categories
-   Context of discriminatory, sociocultural, or biological effects associated with race or SDOH variable used
-   Intersectionality with other variables
:::

:::{.notes}
This is the central point: race is a social construct, not a biological one. There is often more genetic variation within a single racial group than between different groups. When we see health differences by race, we are almost always seeing the downstream effects of systemic factors, like racism, poverty, and environmental exposures. So we must be clear about what we think the race variable is a proxy for in our specific context—-is it racism, culture, or something else?

:::

## Race and Ethnicity: Recommendations

::: {.incremental .highlight-last}
-   Use clearly defined categories, standard and not collapsed categories when possible
    -   Avoid collapsing categories of race with disparate health outcomes
    -   Avoid label "other", use descriptive terms for collapsed categories
    -   Include ethnicity and ancestry information
-   Clearly document data collection and classification methods
-   If using race as a confounder, covariate, or adjustment variable, examine effect modification
-   Acknowledge limitations
:::

[Urban Institute: Using Race and Ethnicity Data to Advance Health Equity](https://www.urban.org/research/publication/using-race-and-ethnicity-data-advance-health-equity)

`r Cite(key = "swilley2023we", bib=myBib, textual = TRUE, .opts=list(cite.style="authoryear"))`


:::{.notes}
So what should we do? First, use clearly defined categories and avoid collapsing them when possible, especially if the groups have disparate health outcomes. The label 'Other' is particularly problematic; it's better to use descriptive terms for collapsed groups. We should also clearly document how this data was collected. And critically, if you are using race as a variable in your model, you should almost always check for effect modification—meaning, does the effect you're studying differ across racial groups? We'll come back to this in a bit. And of course, always acknolwedge limitations of the variables you're collecting and using in your study.
:::

# Social Determinants of Health  (SDOH)

![](img/Healthy%20People%202030%20SDOH%20Graphic%20Domain%20Labels.png)

[US Dept of Health & Human Services: Healthy People 2030](https://odphp.health.gov/healthypeople/priority-areas/social-determinants-health)

:::{.notes}
This conversation about race as a social construct leads directly to Social Determinants of Health, or SDOH.

As defined by Healthy People 2030, SDOH are the conditions in the environments where people are born, live, learn, work, and play that affect a wide range of health outcomes. This includes things like economic stability, access to education and healthcare, and the neighborhood environment. These factors are often the actual drivers of the health disparities we sometimes incorrectly attribute to race.
:::

## Social Determinants of Health


::::: columns
::: {.column width="50%"}

### Design and data considerations

::: {.incremental .highlight-last}
-   Equitable sampling
-   Missing data issues
-   Granular data collection
-   Standardization of variable definitions
-   Document contextual factors
:::

::: {.fragment}
### Analysis strategies

::: {.incremental .highlight-last}
-   Including SDOH variables in models can be complex
-   Consider mediating effects or effect modification
-   Consider correlation/collinearity
-   Address missing data
:::

`r Cite(key = "braveman2023social", bib=myBib, textual = TRUE, .opts=list(cite.style="authoryear"))`
:::
:::

::: {.column width="50%"}

![](img/hillside.png)
:::
::::

:::{.notes}
Incorporating SDOH into our models is a huge step forward, but it comes with its own challenges. It requires equitable sampling, granular data collection, and standardized definitions. Analytically, we have to consider that many SDOH variables are correlated. For example, income, education, and neighborhood are all linked. We need to think carefully about whether these variables are confounders, mediators, or effect modifiers in our causal pathway.
:::

# Statistical Analysis Considerations

We adjusted for ....

:::{.notes}
"This brings us to the statistical analysis itself. When we say we 'adjusted for' or 'controlled for' something, what do we actually mean?"
:::

## Statistical Analysis, Adjustment


What does controlling for race (or sex, or gender, or SDOH) mean?

::: {.incremental .highlight-last}
-   Adjustment, matching, stratification, etc. estimates effects over all strata to present an overall effect between exposure and outcome

-   When adjusting for the social construct of race, the adjusted effect estimate can be interpreted as the exposure-outcome relationship if racism did not affect the exposure

-   Pooled effects are weighted toward the larger group

-   Effect measure modification allows for different effects within groups (race, gender, sex, etc)
:::

`r Cite(key = "swilley2023we", bib=myBib, textual = TRUE, .opts=list(cite.style="authoryear"))`

:::{.notes}
In statistical terms, adjustment gives us an overall, or average, effect of an exposure on an outcome, after accounting for the influence of other variables. When we adjust for the social construct of race, the interpretation can be tricky. One way to think about it is that the adjusted estimate represents the relationship we'd see if racism didn't exist or didn't affect the exposure.

But this pooled effect is often weighted toward the majority group in the sample, potentially masking a very different effect in a smaller group. This is why we should consider effect measure modification. Instead of calculating one 'average' effect for everyone, this approach allows us to estimate different effects for different groups, which is often more insightful
:::

## Model and Interpretation Considerations

::::: columns
::: {.column width="50%"}
### Model Development

::: {.incremental .highlight-last}
-   Variable selection and coding
-   Interaction testing
-   Missing data patterns
-   Model assumptions
:::

::: {.fragment}

### Interpretation

::: {.incremental .highlight-last}
-   Effect modification
-   Confounding
-   Mediation
-   Population-specific effects
:::

:::

:::
::: {.column width="50%"}
![](img/team_meet.png)

:::
::::

:::{.notes}
"This requires us to be thoughtful in our model development—paying close attention to how we select and code variables, and whether we test for interactions, which can be a way of testing effect modification.We also need to be careful to consider missing data patterns and model assumptions. And in our interpretation, we need to be clear about whether we're talking about confounding, mediation, or effect modification."
:::

## Modeling Decisions

::: {.fragment}

**Bivariate Model: Y~X**

::: {.incremental .highlight-last}
- Use when asking "Does a demographic group receive access at different rates?"
:::
:::

::: {.fragment}

**Multiple Regression Y~X+Z**

::: {.incremental .highlight-last}
- Use when asking "Do similarly situated individuals access benefits at the same rate?"
:::
:::

:::{.notes}
Let’s simplify this with a clear choice. When should you use a simple, bivariate model versus a more complex, multiple regression model?

A Bivariate Model, where we just have outcome Y regressed on one variable X, such as race, is best when you're asking: 'Does a disparity exist? Do different demographic groups experience different outcomes or receive access to care at different rates?'  This is often an important first question.

A Multiple Regression Model, where our outcome Y is regressed on multiple variables including the factor of interest X as well as other measures, Z, is for when you're asking a different question. That is, 'Do similarly situated individuals still experience different outcomes?' Or, do people with the same Z values, still experience different outcomes? This model attempts to get closer to the 'why'."
:::


# Modeling Examples

[Interactive App](https://minnier.shinyapps.io/equity_regression/)

![](img/prof_business_memeting.png)

:::{.notes}
"Let's make this more concrete with a few examples."
:::

## Example 1: Postoperative Opioid Prescribing


-   **Research Question:** Are there racial disparities in the amount of opioids prescribed to patients at discharge after a total knee arthroplasty?
-   **Outcome (Y):** Total morphine milligram equivalents (MME) prescribed.
-   **Attribute of Interest (X):** Patient race (e.g., Black vs. White).

::::: columns
::: {.column width="50%"}
::: {.fragment}
***Bivariate Regression Model:***

`lm(MME ~ patient_race, data = surgical_data)`

**Interpretation:** "On average, do Black patients receive different MME prescriptions at discharge compared to White patients?"
:::
:::

::: {.column width="50%"}
::: {.fragment}
***Multiple Regression Model:***

`lm(MME ~ patient_race + preoperative_pain_score + procedure_time, data = surgical_data)`

**Interpretation:** "Among patients with similar pre-op pain and procedure times, is there still a difference in MME prescriptions between Black and White patients?"
:::
:::
:::::

:::{.notes}
Research Question: Are there racial disparities in the amount of opioids prescribed at discharge after a total knee arthroplasty? Our outcome is the total Morphine Milligram Equivalents, or MME, and our attribute of interest is patient race.

The bivariate model simply asks: 'On average, do Black patients get different MME prescriptions than White patients?' 

The multiple regression model adds in covariates or adjustment variables like pre-operative pain scores and procedure time. It asks: 'Among patients with 
similar pain and procedure times, is there still a difference in prescribing between Black and White patients?
:::

## Discussion: Post-attribute Bias

Be cautious controlling for in-hospital patient-reported pain.

:::{.incremental .highlight-last}
-   If provider bias (related to race) leads to under-treatment of pain, the Black patient might report higher pain scores.
-   Controlling for this pain score could incorrectly make a lower MME prescription seem medically justified, thereby masking the original bias.
-   The bivariate model may be more appropriate. 
-   In this case the "race" effect could be the effect of systemic racism.
:::

:::{.fragrment}
**Post-attribute bias** occurs when we control for variables that may be affected by the attribute we’re studying (a.k.a. post-treatment bias, intermediate variable bias, mediating variable bias)
:::

:::{.notes}
But we have to be very careful here. What if we control for in-hospital patient-reported pain? This is where we can run into post-attribute bias. Provider bias, which is associated with patient race, might lead to the under-treatment of pain for a Black patient during their hospital stay. This patient might then report a higher pain score. If we 'control' for that pain score, we might incorrectly conclude that a lower MME prescription was medically justified, when in fact, we've just masked the effect of the original bias. In this scenario, the simpler bivariate model, which asks if a disparity exists, might be the more honest and appropriate model. The 'race effect' here is really the 'effect of systemic racism'
:::

## Example 2: Use of Regional Anesthesia

-   **Research Question:** Does insurance type influence whether a patient receives regional anesthesia (e.g., a nerve block) for shoulder surgery, which can reduce postoperative pain and opioid use?
-   **Outcome**: Receipt of nerve block (Yes/No, a binary outcome).
-   **Attribute of Interest:** Insurance type (e.g., Private vs. Medicaid).

::::: columns
::: {.column width="50%"}
:::{.fragment}
***Bivariate Regression Model:***

`glm(nerve_block ~ insurance_type, family = "binomial", data = ortho_data)`

**Interpretation:** "On average, are patients with Medicaid less likely to receive a nerve block than patients with private insurance?"
:::
:::

::: {.column width="50%"}
:::{.fragment}
***Multiple Regression Model:***

`glm(nerve_block ~ insurance_type + patient_asa_score + hospital_type, family = "binomial", data = ortho_data)`

**Interpretation:** "Controlling for patient health status (ASA score) and the type of hospital (e.g., teaching vs. non-teaching), are Medicaid patients still less likely to receive a nerve block?"
:::
:::
:::::

:::{.notes}
Research Question: Does insurance type influence whether a patient receives regional anesthesia for shoulder surgery? The outcome is getting a nerve block (Yes/No), and the attribute is insurance type (Private vs. Medicaid).


The bivariate model asks: 'Are Medicaid patients less likely to get a nerve block than patients with private insurance?' 

The multiple regression model controls for patient health status (ASA score) and hospital type. It asks: 'After accounting for health status and hospital type, are Medicaid patients still less likely to receive a nerve block?' 
:::

## Discussion: Omitted Variable Bias

:::{.incremental .highlight-last}
-   Failing to control for patient health status (a key confounder) could lead to incorrect conclusions if, for instance, Medicaid patients in your sample have more comorbidities that contraindicate a nerve block.
-   Insurance is associated with ASA score
-   Hospital type may also be related to use of nerve block or insurance type rates
-   The full model provides a more complete picture.
:::

:::{.notes}
In this case, the more complex model is likely better. Why? Because patient health status is a key confounder. It's plausible that Medicaid patients in a given sample have more comorbidities that would be a contraindication for a nerve block. If we don't control for that, we might mistakenly attribute the difference to insurance type alone. This is called omitted variable bias. Here, the full model gives us a more complete and accurate picture.
:::

## Example 3: 30-Day Hospital Readmission

-   **Research Question:** Are patients with Limited English Proficiency (LEP) at higher risk for readmission after major abdominal surgery?
-   **Outcome**: Readmitted within 30 days (Yes/No).
-   **Attribute of Interest:** LEP status (e.g., needs interpreter vs. English proficient).

::::: columns
::: {.column width="50%"}
:::{.fragment}
***Bivariate Regression Model:***

`glm(readmitted ~ lep_status, family = "binomial", data = surgery_discharge_data)`

**Interpretation:** "Do patients with LEP have a higher 30-day readmission rate?"
:::
:::

::: {.column width="50%"}
:::{.fragment}
***Multiple Regression Model:***

`glm(readmitted ~ lep_status + surgical_complexity + length_of_stay, family = "binomial", data = surgery_discharge_data)`

**Interpretation:** "After accounting for how sick the patient was (surgical complexity, length of stay), does LEP status remain a predictor of readmission?"
:::
:::
:::::

:::{.notes}
Research Question: Are patients with Limited English Proficiency (LEP) at higher risk for readmission after major abdominal surgery? The outcome is readmission within 30 days, and the attribute is LEP status.


The bivariate model asks: 'Do patients with LEP have a higher readmission rate?'  This is the disparity question.

The multiple regression model adjusts for surgical complexity and length of stay. It asks: 'After accounting for how sick the patient was, does LEP status still predict readmission?'

:::

## Discussion: Disparities

-   This highlights the difference between asking "are there disparities?" (bivariate) versus "what are the mechanisms?" (multivariable). The first question is often the most important for identifying a problem that needs fixing.
-   The disparity in readmission may be caused by inadequate discharge communication, which is part of the mechanism of inequity for LEP patients.

:::{.notes}
This example really highlights the difference between asking 'are there disparities?' (the bivariate question) versus 'what are the mechanisms?' (the multivariable question). 

For identifying a problem that needs fixing, the first question is often the most powerful. A disparity in readmission for LEP patients might be caused by inadequate discharge communication. If we control for variables that are part of that mechanism, we might dilute or hide the very problem we're trying to solve."
:::

## Using Regression to Detect Discrimination

:::{.incremental .highlight-last}
-   Cannot definitively prove discrimination
-   Cannot definitively prove lack of discrimination
-   Unmeasured variables may explain disparities
-   Need robust research design for causal claims
:::

:::{.notes}
A word of caution. While these methods are powerful for identifying disparities, regression alone can never definitively prove discrimination, nor can it prove a lack of discrimination. There are always unmeasured variables. For strong causal claims, we need a robust research design that goes beyond standard regression.
:::

## Best Practices for Reporting

-   Sex and Gender Equity in Research (SAGER) Guidelines `r Cite(key = "heidari2016sex", bib=myBib, textual = TRUE, .opts=list(cite.style="authoryear"))`
-   Race, ethnicity guidelines often journal or study design specific `r Cite(key = "flanagin2021updated", bib=myBib, textual = TRUE, .opts=list(cite.style="authoryear"))`

### Updated Guidelines

-   [STROBE-Equity Statement (2023)](https://methods.cochrane.org/equity/projects/strobe-equity)
-   [CONSORT-Equity Guidelines (2017)](https://www.equator-network.org/reporting-guidelines/consort-equity/)
-   [PRISMA-Equity Extension (2012)](https://www.prisma-statement.org/equity)

:::{.notes}
When it comes time to publish, there are excellent guidelines to help you do this equitably. The SAGER guidelines are for sex and gender equity. And for equity more broadly, the STROBE-Equity, CONSORT-Equity, and PRISMA-Equity statements are fantastic resources for observational studies, trials, and systematic reviews, respectively.
:::

## Perspective

::::: columns
::: {.column width="50%"}
![](img/do_no_harm_addtional.png){fig-alt="Urban Institute's Do No Harm Guide Cover"}
:::

::: {.column width="50%"}
> Data and data projects can only be made more equitable if work teams are diverse, reflect a variety of experiences, and trained to foreground empathy and equity in their work.

[Urban Institute's Do No Harm Guide: Additional Perspectives on Data Equity](https://www.urban.org/research/publication/do-no-harm-guide-additional-perspectives-data-equity)
:::
:::::

:::{.notes}
I want to leave you with this thought from the Urban Institute's 'Do No Harm Guide', which is that 'Data and data projects can only be made more equitable if work teams are diverse, reflect a variety of experiences, and are trained to foreground empathy and equity in their work'. This reminds us that data equity isn't just about methods; it's about people and perspectives.
:::

## References

```{r}
#| results: "asis"
PrintBibliography(myBib)
```

:::{.notes}
"The references I've mentioned are all listed here for your review."
:::

## Thank you!

### Contact info:

-   Jessica Minnier: *minnier\@ohsu.edu*

### This talk info:

-   Slides: [bit.ly/apom_data_eq](https://bit.ly/apom_data_eq)
-   Code for these slides are on github, with links to other talks and course materials: [jminnier/talks_etc](https://github.com/jminnier/talks_etc)
-   Uncited art from [lummi.ai](https://www.lummi.ai/s/illustration/)

:::{.notes}
To summarize, data equity is an active, continuous process. It requires us to question our assumptions, be intentional in our methods, and be honest in our interpretations. It pushes us to move from simply asking 'what is the average effect?' to asking 'for whom does this work, and why?'

Thank you so much for your time and attention. I'd be happy to take any questions
:::
